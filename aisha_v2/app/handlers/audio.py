# --- LEGACY: —É—Å—Ç–∞—Ä–µ–≤—à–∏–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –∞—É–¥–∏–æ, –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å ---
# –í—Å—è –ª–æ–≥–∏–∫–∞ –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω–∞ –≤ TranscriptProcessingHandler
# –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏, –Ω–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å!
# ...

from typing import Optional
from aiogram import Bot, Router, F
from aiogram.types import Message, FSInputFile
from aiogram.filters import Command, StateFilter
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup

from aisha_v2.app.core.logger import logger
from aisha_v2.app.services.storage.minio import MinioStorage

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è FSM
class AudioStates(StatesGroup):
    waiting_for_audio = State()

# –°–æ–∑–¥–∞–µ–º —Ä–æ—É—Ç–µ—Ä
router = Router()

class AudioHandler:
    def __init__(
        self,
        bot: Bot,
        minio_storage: MinioStorage
    ):
        self.bot = bot
        self.minio_storage = minio_storage

    async def handle_audio_start(self, message: Message, state: FSMContext) -> None:
        """–í–∫–ª—é—á–∞–µ—Ç —Ä–µ–∂–∏–º –æ–∂–∏–¥–∞–Ω–∏—è –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞."""
        try:
            await state.set_state(AudioStates.waiting_for_audio)
            await message.answer(
                "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª (mp3/ogg) –¥–ª—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∏."
            )
        except Exception as e:
            logger.exception(f"[handle_audio_start] –û—à–∏–±–∫–∞: {e}")
            await message.answer(
                "–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ—Ö–æ–¥–µ –≤ —Ä–µ–∂–∏–º –∞—É–¥–∏–æ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑."
            )

    async def handle_audio(self, message: Message, state: FSMContext) -> None:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∞—É–¥–∏–æ—Ñ–∞–π–ª—ã –∏ –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è."""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        current_state = await state.get_state()
        if current_state != AudioStates.waiting_for_audio:
            await message.answer(
                "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º '–ê—É–¥–∏–æ' –≤ –º–µ–Ω—é (–∫–Ω–æ–ø–∫–∞ üé§ –ê—É–¥–∏–æ)."
            )
            return

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø —Å–æ–æ–±—â–µ–Ω–∏—è
        if not (message.voice or message.audio):
            await message.answer(
                "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–ª–∏ –∞—É–¥–∏–æ—Ñ–∞–π–ª."
            )
            return

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –Ω–∞—á–∞–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        status_message = await message.answer(AUDIO_PROCESSING_START)

        try:
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—É–¥–∏–æ
            success, error, transcript_path = await self.audio_service.process_audio(
                message=message,
                bot=self.bot,
                user_id=str(message.from_user.id)
            )

            if not success:
                error_msg = AUDIO_PROCESSING_ERROR
                if error == "file_too_large":
                    error_msg = "‚ùå –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: 20 –ú–ë."
                elif error == "ffmpeg_not_found":
                    error_msg = "‚ùå –û—à–∏–±–∫–∞: ffmpeg –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω."
                elif error == "unsupported_format":
                    error_msg = "‚ùå –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç –∞—É–¥–∏–æ."
                
                await status_message.edit_text(error_msg)
                return

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç
            # --- LEGACY: –æ—Ç–ø—Ä–∞–≤–∫–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–µ—Ç–∞–ª–µ–π/—Å—ã—Ä–æ–≥–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é ---
            # if transcript_path:
            #     with open(transcript_path, "r", encoding="utf-8") as f:
            #         transcript_text = f.read()
            #     await message.answer_document(
            #         document=FSInputFile(transcript_path),
            #         caption=AUDIO_PROCESSING_DONE.format(
            #             snippet=transcript_text[:200]
            #         )
            #     )
            # --- END LEGACY ---
            # –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ TranscriptProcessingHandler –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ UX

        except Exception as e:
            logger.exception(f"[handle_audio] –û—à–∏–±–∫–∞: {e}")
            await status_message.edit_text(AUDIO_PROCESSING_ERROR)
            
        finally:
            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            await state.clear()

# –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º —Ö–µ–Ω–¥–ª–µ—Ä—ã
def register_handlers(handler: AudioHandler):
    router.message.register(
        handler.handle_audio_start,
        Command("audio")
    )
    router.message.register(
        handler.handle_audio,
        StateFilter(AudioStates.waiting_for_audio),
        F.voice | F.audio
    ) 