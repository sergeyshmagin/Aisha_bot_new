#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ MinIO

–ü—Ä–æ–±–ª–µ–º–∞: –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ñ–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º "generated/" –≤ –ø—É—Ç–∏,
–Ω–æ URL –≤ –ë–î —É–∫–∞–∑—ã–≤–∞—é—Ç –Ω–∞ –ø—É—Ç–∏ –±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞, —á—Ç–æ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ 404 –æ—à–∏–±–∫–∞–º.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python scripts/fix_minio_urls.py --check       # –¢–æ–ª—å–∫–æ –ø—Ä–æ–≤–µ—Ä–∫–∞
    python scripts/fix_minio_urls.py --fix         # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º
"""

import asyncio
import sys
import argparse
from pathlib import Path
import logging

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ Python path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from app.core.database import get_session
from app.core.config import settings
from app.services.storage.minio import MinioStorage
from app.repositories.generation_repository import ImageGenerationRepository
from sqlalchemy import select, update
from app.models.generation import ImageGeneration

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class MinioUrlFixer:
    """–£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö URL –≤ MinIO"""
    
    def __init__(self):
        self.storage = MinioStorage()
        self.fixed_count = 0
        self.problem_count = 0
        
    async def check_and_fix_urls(self, fix_mode: bool = False):
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ URLs
        
        Args:
            fix_mode: True - –∏—Å–ø—Ä–∞–≤–ª—è—Ç—å –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã, False - —Ç–æ–ª—å–∫–æ –ø—Ä–æ–≤–µ—Ä—è—Ç—å
        """
        logger.info(f"üîç –ó–∞–ø—É—Å–∫ {'–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è' if fix_mode else '–ø—Ä–æ–≤–µ—Ä–∫–∏'} URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ MinIO...")
        
        async with get_session() as session:
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å result_urls
            query = select(ImageGeneration).where(
                ImageGeneration.result_urls.isnot(None),
                ImageGeneration.result_urls != []
            )
            result = await session.execute(query)
            generations = result.scalars().all()
            
            logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(generations)} –≥–µ–Ω–µ—Ä–∞—Ü–∏–π —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏")
            
            problems_found = []
            
            for generation in generations:
                if not generation.result_urls:
                    continue
                    
                for i, url in enumerate(generation.result_urls):
                    if not url or not url.startswith('http'):
                        continue
                        
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º URL
                    problem_type = await self._analyze_url(url)
                    
                    if problem_type:
                        self.problem_count += 1
                        problem_info = {
                            'generation_id': generation.id,
                            'url_index': i,
                            'old_url': url,
                            'problem_type': problem_type
                        }
                        
                        logger.warning(f"‚ö†Ô∏è  –ü—Ä–æ–±–ª–µ–º–∞ #{self.problem_count}: {problem_type}")
                        logger.warning(f"   –ì–µ–Ω–µ—Ä–∞—Ü–∏—è: {generation.id}")
                        logger.warning(f"   URL: {url[:80]}...")
                        
                        if fix_mode:
                            # –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø—Ä–∞–≤–∏—Ç—å URL
                            fixed_url = await self._fix_url(url, problem_type)
                            if fixed_url and fixed_url != url:
                                # –û–±–Ω–æ–≤–ª—è–µ–º URL –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
                                new_result_urls = generation.result_urls.copy()
                                new_result_urls[i] = fixed_url
                                
                                await session.execute(
                                    update(ImageGeneration)
                                    .where(ImageGeneration.id == generation.id)
                                    .values(result_urls=new_result_urls)
                                )
                                
                                self.fixed_count += 1
                                logger.info(f"‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ #{self.fixed_count}: {generation.id}")
                                logger.info(f"   –ù–æ–≤—ã–π URL: {fixed_url[:80]}...")
                            else:
                                logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏—Å–ø—Ä–∞–≤–∏—Ç—å URL –¥–ª—è {generation.id}")
                        
                        problems_found.append(problem_info)
            
            if fix_mode and self.fixed_count > 0:
                await session.commit()
                logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {self.fixed_count} –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö")
            
        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        logger.info(f"üìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã {'–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è' if fix_mode else '–ø—Ä–æ–≤–µ—Ä–∫–∏'}:")
        logger.info(f"   üîç –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–π: {len(generations)}")
        logger.info(f"   ‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º: {self.problem_count}")
        
        if fix_mode:
            logger.info(f"   ‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: {self.fixed_count}")
            logger.info(f"   ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏—Å–ø—Ä–∞–≤–∏—Ç—å: {self.problem_count - self.fixed_count}")
        
        return problems_found
    
    async def _analyze_url(self, url: str) -> str:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç URL –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –ø—Ä–æ–±–ª–µ–º
        
        Returns:
            str: –¢–∏–ø –ø—Ä–æ–±–ª–µ–º—ã –∏–ª–∏ None –µ—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º –Ω–µ—Ç
        """
        try:
            import urllib.parse
            
            # –ü–∞—Ä—Å–∏–º URL
            parsed_url = urllib.parse.urlparse(url)
            path_parts = parsed_url.path.strip('/').split('/', 1)
            
            if len(path_parts) < 2:
                return "invalid_format"
            
            bucket = path_parts[0]
            object_name = path_parts[1]
            
            if bucket != "generated":
                return None  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ generated bucket
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –ø–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º—É –ø—É—Ç–∏
            try:
                test_data = await self.storage.download_file(bucket, object_name)
                if test_data and len(test_data) > 0:
                    return None  # –§–∞–π–ª –Ω–∞–π–¥–µ–Ω - –ø—Ä–æ–±–ª–µ–º –Ω–µ—Ç
            except:
                pass
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º generated/
            if not object_name.startswith("generated/"):
                try:
                    prefixed_object_name = f"generated/{object_name}"
                    test_data = await self.storage.download_file(bucket, prefixed_object_name)
                    if test_data and len(test_data) > 0:
                        return "missing_prefix"  # –§–∞–π–ª –µ—Å—Ç—å —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º
                except:
                    pass
            
            return "file_not_found"  # –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –≤–æ–æ–±—â–µ
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ URL {url}: {e}")
            return "analysis_error"
    
    async def _fix_url(self, old_url: str, problem_type: str) -> str:
        """
        –ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –ø—Ä–æ–±–ª–µ–º–Ω—ã–π URL
        
        Args:
            old_url: –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π URL
            problem_type: –¢–∏–ø –ø—Ä–æ–±–ª–µ–º—ã
            
        Returns:
            str: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π URL –∏–ª–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –µ—Å–ª–∏ –∏—Å–ø—Ä–∞–≤–∏—Ç—å –Ω–µ —É–¥–∞–ª–æ—Å—å
        """
        try:
            if problem_type == "missing_prefix":
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–≤—ã–π presigned URL —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –ø—É—Ç—ë–º
                import urllib.parse
                
                parsed_url = urllib.parse.urlparse(old_url)
                path_parts = parsed_url.path.strip('/').split('/', 1)
                
                if len(path_parts) >= 2:
                    bucket = path_parts[0]
                    object_name = path_parts[1]
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ—Ñ–∏–∫—Å –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –ø—É—Ç–∏
                    corrected_object_name = f"generated/{object_name}"
                    
                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–≤—ã–π presigned URL
                    new_url = await self.storage.generate_presigned_url(
                        bucket=bucket,
                        object_name=corrected_object_name,
                        expires=86400  # 1 –¥–µ–Ω—å
                    )
                    
                    return new_url if new_url else old_url
            
            return old_url
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è URL {old_url}: {e}")
            return old_url


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å–∫—Ä–∏–ø—Ç–∞"""
    parser = argparse.ArgumentParser(description='–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ MinIO')
    parser.add_argument('--check', action='store_true', help='–¢–æ–ª—å–∫–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ –ø—Ä–æ–±–ª–µ–º')
    parser.add_argument('--fix', action='store_true', help='–ò—Å–ø—Ä–∞–≤–∏—Ç—å –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã')
    
    args = parser.parse_args()
    
    if not args.check and not args.fix:
        parser.print_help()
        return
    
    if args.check and args.fix:
        logger.error("‚ùå –í—ã–±–µ—Ä–∏—Ç–µ –æ–¥–∏–Ω —Ä–µ–∂–∏–º: --check –∏–ª–∏ --fix")
        return
    
    fixer = MinioUrlFixer()
    
    try:
        problems = await fixer.check_and_fix_urls(fix_mode=args.fix)
        
        if args.check and problems:
            logger.info(f"üí° –î–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è {len(problems)} –ø—Ä–æ–±–ª–µ–º –∑–∞–ø—É—Å—Ç–∏—Ç–µ: python scripts/fix_minio_urls.py --fix")
        
    except Exception as e:
        logger.exception(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main()) 