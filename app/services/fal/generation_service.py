"""
–°–µ—Ä–≤–∏—Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å FAL AI
"""
import asyncio
from typing import Dict, List, Optional, Any
from uuid import UUID

import fal_client

from ...core.config import settings
from ...core.logger import get_logger
from ...database.models import Avatar, AvatarTrainingType

logger = get_logger(__name__)


class FALGenerationService:
    """
    –°–µ—Ä–≤–∏—Å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –æ–±—É—á–µ–Ω–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ FAL AI.
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
    - –ü–æ—Ä—Ç—Ä–µ—Ç–Ω—ã–µ –∞–≤–∞—Ç–∞—Ä—ã (LoRA —Ñ–∞–π–ª—ã)
    - –°—Ç–∏–ª–µ–≤—ã–µ –∞–≤–∞—Ç–∞—Ä—ã (finetune_id)
    - –¢–µ—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º
    """

    def __init__(self):
        self.api_key = settings.FAL_API_KEY
        self.test_mode = settings.AVATAR_TEST_MODE
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º FAL –∫–ª–∏–µ–Ω—Ç
        if self.api_key:
            fal_client.api_key = self.api_key
        else:
            logger.debug("FAL_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, —Ä–∞–±–æ—Ç–∞ –≤ —Ç–µ—Å—Ç–æ–≤–æ–º —Ä–µ–∂–∏–º–µ")

    async def generate_avatar_image(
        self,
        avatar: Avatar,
        prompt: str,
        generation_config: Optional[Dict[str, Any]] = None
    ) -> Optional[str]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –æ–±—É—á–µ–Ω–Ω—ã–º –∞–≤–∞—Ç–∞—Ä–æ–º
        
        Args:
            avatar: –ú–æ–¥–µ–ª—å –∞–≤–∞—Ç–∞—Ä–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ –æ–±—É—á–µ–Ω–∏—è
            prompt: –ü—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            generation_config: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            
        Returns:
            Optional[str]: URL —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            
        Raises:
            ValueError: –ü—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
            RuntimeError: –ü—Ä–∏ –æ—à–∏–±–∫–∞—Ö –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        """
        try:
            if self.test_mode:
                logger.info(f"[FAL TEST MODE] –°–∏–º—É–ª—è—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –∞–≤–∞—Ç–∞—Ä–∞ {avatar.id}")
                return await self._simulate_generation(avatar, prompt)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∞–≤–∞—Ç–∞—Ä –æ–±—É—á–µ–Ω
            if not self._is_avatar_trained(avatar):
                raise ValueError(f"–ê–≤–∞—Ç–∞—Ä {avatar.id} –Ω–µ –æ–±—É—á–µ–Ω –∏–ª–∏ –æ–±—É—á–µ–Ω–∏–µ –Ω–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
            
            # –í—ã–±–∏—Ä–∞–µ–º –º–µ—Ç–æ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∞–≤–∞—Ç–∞—Ä–∞
            if avatar.training_type == AvatarTrainingType.PORTRAIT:
                return await self._generate_with_lora(avatar, prompt, generation_config)
            else:
                return await self._generate_with_finetune(avatar, prompt, generation_config)
                
        except Exception as e:
            logger.exception(f"[FAL AI] –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –∞–≤–∞—Ç–∞—Ä–∞ {avatar.id}: {e}")
            raise

    async def _generate_with_lora(
        self,
        avatar: Avatar,
        prompt: str,
        config: Optional[Dict[str, Any]] = None
    ) -> Optional[str]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å LoRA —Ñ–∞–π–ª–æ–º (–¥–ª—è –ø–æ—Ä—Ç—Ä–µ—Ç–Ω—ã—Ö –∞–≤–∞—Ç–∞—Ä–æ–≤)
        
        Args:
            avatar: –ü–æ—Ä—Ç—Ä–µ—Ç–Ω—ã–π –∞–≤–∞—Ç–∞—Ä —Å LoRA —Ñ–∞–π–ª–æ–º
            prompt: –ü—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            config: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            
        Returns:
            Optional[str]: URL —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        """
        if not avatar.diffusers_lora_file_url:
            raise ValueError(f"LoRA —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è –∞–≤–∞—Ç–∞—Ä–∞ {avatar.id}")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç —Å —Ç—Ä–∏–≥–≥–µ—Ä–Ω–æ–π —Ñ—Ä–∞–∑–æ–π
        full_prompt = self._build_prompt_with_trigger(prompt, avatar.trigger_phrase)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è LoRA
        generation_args = {
            "prompt": full_prompt,
            "lora_url": avatar.diffusers_lora_file_url,
            "lora_scale": config.get("lora_scale", 1.0) if config else 1.0,
            "num_images": config.get("num_images", 1) if config else 1,
            "image_size": config.get("image_size", "square_hd") if config else "square_hd",
            "num_inference_steps": config.get("num_inference_steps", 28) if config else 28,
            "guidance_scale": config.get("guidance_scale", 3.5) if config else 3.5,
            "enable_safety_checker": config.get("enable_safety_checker", True) if config else True,
        }
        
        logger.info(f"[FAL AI] –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å LoRA –¥–ª—è –∞–≤–∞—Ç–∞—Ä–∞ {avatar.id}: {generation_args}")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
        result = await asyncio.get_event_loop().run_in_executor(
            None,
            lambda: fal_client.subscribe(
                "fal-ai/flux-lora",
                arguments=generation_args
            )
        )
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        images = result.get("images", [])
        if images and len(images) > 0:
            image_url = images[0].get("url")
            logger.info(f"[FAL AI] LoRA –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {image_url}")
            return image_url
        
        logger.warning(f"[FAL AI] –ù–µ –ø–æ–ª—É—á–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ LoRA –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
        return None

    async def _generate_with_finetune(
        self,
        avatar: Avatar,
        prompt: str,
        config: Optional[Dict[str, Any]] = None
    ) -> Optional[str]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å finetune_id (–¥–ª—è —Ö—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∞–≤–∞—Ç–∞—Ä–æ–≤)
        
        Args:
            avatar: –•—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –∞–≤–∞—Ç–∞—Ä —Å finetune_id
            prompt: –ü—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            config: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            
        Returns:
            Optional[str]: URL —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        """
        if not avatar.finetune_id:
            raise ValueError(f"Finetune ID –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è –∞–≤–∞—Ç–∞—Ä–∞ {avatar.id}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Ultra –º–æ–¥–µ–ª—å
        use_ultra = config and config.get("use_ultra", False) if config else False
        
        if use_ultra:
            return await self._generate_with_finetune_ultra(avatar, prompt, config)
        else:
            return await self._generate_with_finetune_standard(avatar, prompt, config)

    async def _generate_with_finetune_standard(
        self,
        avatar: Avatar,
        prompt: str,
        config: Optional[Dict[str, Any]] = None
    ) -> Optional[str]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–π FLUX.1 [pro] finetuned –º–æ–¥–µ–ª—å—é
        """
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç —Å —Ç—Ä–∏–≥–≥–µ—Ä–Ω—ã–º —Å–ª–æ–≤–æ–º
        full_prompt = self._build_prompt_with_trigger(prompt, avatar.trigger_word)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è finetune
        generation_args = {
            "prompt": full_prompt,
            "finetune_id": avatar.finetune_id,  # –ò–°–ü–†–ê–í–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º finetune_id –≤–º–µ—Å—Ç–æ model
            "finetune_strength": config.get("finetune_strength", 1.0) if config else 1.0,
            "num_images": config.get("num_images", 1) if config else 1,
            "image_size": config.get("image_size", "square_hd") if config else "square_hd",
            "num_inference_steps": config.get("num_inference_steps", 28) if config else 28,
            "guidance_scale": config.get("guidance_scale", 3.5) if config else 3.5,
            "safety_tolerance": config.get("safety_tolerance", "2") if config else "2",
            "output_format": config.get("output_format", "jpeg") if config else "jpeg",
        }
        
        logger.info(f"[FAL AI] –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å finetune –¥–ª—è –∞–≤–∞—Ç–∞—Ä–∞ {avatar.id}: {generation_args}")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º endpoint
        result = await asyncio.get_event_loop().run_in_executor(
            None,
            lambda: fal_client.subscribe(
                "fal-ai/flux-pro/finetuned",  # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π endpoint
                arguments=generation_args
            )
        )
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        images = result.get("images", [])
        if images and len(images) > 0:
            image_url = images[0].get("url")
            logger.info(f"[FAL AI] Finetune –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {image_url}")
            return image_url
        
        logger.warning(f"[FAL AI] –ù–µ –ø–æ–ª—É—á–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ finetune –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
        return None

    async def _generate_with_finetune_ultra(
        self,
        avatar: Avatar,
        prompt: str,
        config: Optional[Dict[str, Any]] = None
    ) -> Optional[str]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å FLUX.1 [pro] v1.1-ultra-finetuned –º–æ–¥–µ–ª—å—é
        
        Args:
            avatar: –•—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –∞–≤–∞—Ç–∞—Ä —Å finetune_id
            prompt: –ü—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            config: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            
        Returns:
            Optional[str]: URL —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        """
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç —Å —Ç—Ä–∏–≥–≥–µ—Ä–Ω—ã–º —Å–ª–æ–≤–æ–º
        full_prompt = self._build_prompt_with_trigger(prompt, avatar.trigger_word)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è Ultra –º–æ–¥–µ–ª–∏
        generation_args = {
            "prompt": full_prompt,
            "finetune_id": avatar.finetune_id,
            "finetune_strength": config.get("finetune_strength", 1.1) if config else 1.1,
            "aspect_ratio": config.get("aspect_ratio", "1:1") if config else "1:1",
            "num_images": config.get("num_images", 1) if config else 1,
            "output_format": config.get("output_format", "jpeg") if config else "jpeg",
            "enable_safety_checker": config.get("enable_safety_checker", True) if config else True,
            "raw": config.get("raw", False) if config else False,
        }
        
        logger.info(f"[FAL AI] Ultra –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–ª—è –∞–≤–∞—Ç–∞—Ä–∞ {avatar.id}: {generation_args}")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Å Ultra endpoint
        result = await asyncio.get_event_loop().run_in_executor(
            None,
            lambda: fal_client.subscribe(
                "fal-ai/flux-pro/v1.1-ultra-finetuned",
                arguments=generation_args
            )
        )
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        images = result.get("images", [])
        if images and len(images) > 0:
            image_url = images[0].get("url")
            logger.info(f"[FAL AI] Ultra –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {image_url}")
            return image_url
        
        logger.warning(f"[FAL AI] –ù–µ –ø–æ–ª—É—á–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ Ultra –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
        return None

    async def _simulate_generation(
        self,
        avatar: Avatar,
        prompt: str
    ) -> str:
        """
        –°–∏–º—É–ª—è—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Ä–µ–∂–∏–º–∞
        
        Args:
            avatar: –ê–≤–∞—Ç–∞—Ä
            prompt: –ü—Ä–æ–º–ø—Ç
            
        Returns:
            str: –¢–µ—Å—Ç–æ–≤—ã–π URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        """
        # –ò–º–∏—Ç–∏—Ä—É–µ–º –∑–∞–¥–µ—Ä–∂–∫—É –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        await asyncio.sleep(2)
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π URL —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        test_url = (
            f"https://picsum.photos/1024/1024?random={avatar.id}&"
            f"type={avatar.training_type.value}&prompt={hash(prompt) % 1000}"
        )
        
        logger.info(f"üß™ [FAL TEST MODE] –°–∏–º—É–ª—è—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {test_url}")
        return test_url

    def _is_avatar_trained(self, avatar: Avatar) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —á—Ç–æ –∞–≤–∞—Ç–∞—Ä –æ–±—É—á–µ–Ω –∏ –≥–æ—Ç–æ–≤ –∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        
        Args:
            avatar: –ê–≤–∞—Ç–∞—Ä –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            
        Returns:
            bool: True –µ—Å–ª–∏ –∞–≤–∞—Ç–∞—Ä –≥–æ—Ç–æ–≤ –∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        """
        from ...database.models import AvatarStatus
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å
        if avatar.status != AvatarStatus.COMPLETED:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
        if avatar.training_type == AvatarTrainingType.PORTRAIT:
            return bool(avatar.diffusers_lora_file_url)
        else:
            return bool(avatar.finetune_id)

    def _build_prompt_with_trigger(
        self,
        prompt: str,
        trigger: Optional[str]
    ) -> str:
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç —Ç—Ä–∏–≥–≥–µ—Ä–Ω—É—é —Ñ—Ä–∞–∑—É/—Å–ª–æ–≤–æ –∫ –ø—Ä–æ–º–ø—Ç—É
        
        Args:
            prompt: –ò—Å—Ö–æ–¥–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            trigger: –¢—Ä–∏–≥–≥–µ—Ä–Ω–∞—è —Ñ—Ä–∞–∑–∞ –∏–ª–∏ —Å–ª–æ–≤–æ
            
        Returns:
            str: –ü—Ä–æ–º–ø—Ç —Å —Ç—Ä–∏–≥–≥–µ—Ä–æ–º
        """
        if not trigger:
            return prompt
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ç—Ä–∏–≥–≥–µ—Ä –µ—â–µ –Ω–µ –≤ –ø—Ä–æ–º–ø—Ç–µ
        if trigger.lower() in prompt.lower():
            return prompt
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç—Ä–∏–≥–≥–µ—Ä –≤ –Ω–∞—á–∞–ª–æ –ø—Ä–æ–º–ø—Ç–∞
        return f"{trigger} {prompt}"

    async def generate_multiple_images(
        self,
        avatar: Avatar,
        prompts: List[str],
        generation_config: Optional[Dict[str, Any]] = None
    ) -> List[Optional[str]]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –æ–¥–Ω–æ–≥–æ –∞–≤–∞—Ç–∞—Ä–∞
        
        Args:
            avatar: –ê–≤–∞—Ç–∞—Ä –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            prompts: –°–ø–∏—Å–æ–∫ –ø—Ä–æ–º–ø—Ç–æ–≤
            generation_config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            
        Returns:
            List[Optional[str]]: –°–ø–∏—Å–æ–∫ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        """
        results = []
        
        for i, prompt in enumerate(prompts):
            try:
                logger.info(f"[FAL AI] –ì–µ–Ω–µ—Ä–∞—Ü–∏—è {i+1}/{len(prompts)} –¥–ª—è –∞–≤–∞—Ç–∞—Ä–∞ {avatar.id}")
                
                image_url = await self.generate_avatar_image(
                    avatar=avatar,
                    prompt=prompt,
                    generation_config=generation_config
                )
                
                results.append(image_url)
                
                # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –≥–µ–Ω–µ—Ä–∞—Ü–∏—è–º–∏
                if i < len(prompts) - 1:
                    await asyncio.sleep(1)
                    
            except Exception as e:
                logger.exception(f"[FAL AI] –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ {i+1}: {e}")
                results.append(None)
        
        logger.info(
            f"[FAL AI] –ó–∞–≤–µ—Ä—à–µ–Ω–∞ –ø–∞–∫–µ—Ç–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–ª—è –∞–≤–∞—Ç–∞—Ä–∞ {avatar.id}: "
            f"{len([r for r in results if r])}/{len(prompts)} —É—Å–ø–µ—à–Ω–æ"
        )
        
        return results

    def get_generation_config_presets(self) -> Dict[str, Dict[str, Any]]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        
        Returns:
            Dict[str, Dict[str, Any]]: –°–ª–æ–≤–∞—Ä—å —Å –ø—Ä–µ—Å–µ—Ç–∞–º–∏
        """
        return {
            "fast": {
                "num_inference_steps": 20,
                "guidance_scale": 3.0,
                "image_size": "square",
                "lora_scale": 0.8,
                "finetune_strength": 0.8,
                "safety_tolerance": "2",
            },
            "balanced": {
                "num_inference_steps": 28,
                "guidance_scale": 3.5,
                "image_size": "square_hd",
                "lora_scale": 1.0,
                "finetune_strength": 1.0,
                "safety_tolerance": "2",
            },
            "quality": {
                "num_inference_steps": 50,
                "guidance_scale": 4.0,
                "image_size": "square_hd",
                "lora_scale": 1.2,
                "finetune_strength": 1.2,
                "safety_tolerance": "2",
            },
            "ultra": {
                "use_ultra": True,
                "finetune_strength": 1.1,
                "aspect_ratio": "1:1",
                "num_images": 1,
                "output_format": "jpeg",
                "enable_safety_checker": True,
                "raw": False,
                "safety_tolerance": "2",
            },
            "portrait": {
                "num_inference_steps": 35,
                "guidance_scale": 3.5,
                "image_size": "portrait_4_3",
                "lora_scale": 1.1,
                "finetune_strength": 1.1,
                "safety_tolerance": "2",
            },
            "landscape": {
                "num_inference_steps": 30,
                "guidance_scale": 3.5,
                "image_size": "landscape_4_3",
                "lora_scale": 1.0,
                "finetune_strength": 1.0,
                "safety_tolerance": "2",
            },
            "artistic": {
                "num_inference_steps": 35,
                "guidance_scale": 4.0,
                "image_size": "square_hd",
                "lora_scale": 1.3,
                "finetune_strength": 1.3,
                "safety_tolerance": "3",
            },
            "photorealistic": {
                "num_inference_steps": 40,
                "guidance_scale": 3.5,
                "image_size": "square_hd",
                "lora_scale": 0.9,
                "finetune_strength": 0.9,
                "safety_tolerance": "2",
            }
        }

    def is_available(self) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Å–µ—Ä–≤–∏—Å–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        
        Returns:
            bool: True –µ—Å–ª–∏ —Å–µ—Ä–≤–∏—Å –¥–æ—Å—Ç—É–ø–µ–Ω
        """
        if self.test_mode:
            return True
            
        return bool(self.api_key)

    def get_config_summary(self) -> Dict[str, Any]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–≤–æ–¥–∫—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å–µ—Ä–≤–∏—Å–∞
        
        Returns:
            Dict[str, Any]: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞
        """
        return {
            "test_mode": self.test_mode,
            "api_key_set": bool(self.api_key),
            "available": self.is_available(),
            "supported_types": ["portrait", "style"],
            "supported_models": [
                "fal-ai/flux-lora",  # –ü–æ—Ä—Ç—Ä–µ—Ç–Ω—ã–µ –∞–≤–∞—Ç–∞—Ä—ã
                "fal-ai/flux-pro/finetuned",  # –•—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∞–≤–∞—Ç–∞—Ä—ã
                "fal-ai/flux-pro/v1.1-ultra-finetuned"  # Ultra –∫–∞—á–µ—Å—Ç–≤–æ
            ],
            "presets": list(self.get_generation_config_presets().keys()),
            "features": {
                "lora_generation": True,
                "finetune_generation": True,
                "ultra_quality": True,
                "safety_checker": True,
                "multiple_formats": True,
                "custom_sizes": True
            }
        } 